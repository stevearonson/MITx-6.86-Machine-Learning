{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor flow\n",
    "Following: https://www.tensorflow.org/tutorials/keras/basic_text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('reviews_train.tsv', sep='\\t', engine='python')\n",
    "val_data = pd.read_csv('reviews_val.tsv', sep='\\t', engine='python')\n",
    "test_data = pd.read_csv('reviews_test.tsv', sep='\\t', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "token.fit_on_texts(train_data['text'])\n",
    "Xtrain = token.texts_to_sequences(train_data['text'])\n",
    "Xval = token.texts_to_sequences(val_data['text'])\n",
    "Xtest = token.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Need to padd out sequences to common length\n",
    "length = max(map(len, np.concatenate((Xtrain, Xval))))\n",
    "Xtrain = np.array([xi+[0]*(length-len(xi)) for xi in Xtrain])\n",
    "Xval = np.array([xi+[0]*(length-len(xi)) for xi in Xval])\n",
    "Xtest = np.array([xi+[0]*(length-len(xi)) for xi in Xtest])\n",
    "\n",
    "# convert sentiment (y variable) -1,+1 to 0,1\n",
    "ytrain = (train_data['sentiment'] + 1)/2\n",
    "yval = (val_data['sentiment'] + 1)/2\n",
    "ytest = (test_data['sentiment'] + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          240000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 240,289\n",
      "Trainable params: 240,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "vocab_size = 15000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 500 samples\n",
      "WARNING:tensorflow:From C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "4000/4000 [==============================] - 1s 256us/sample - loss: 0.6932 - acc: 0.5070 - val_loss: 0.6929 - val_acc: 0.5180\n",
      "Epoch 2/40\n",
      "4000/4000 [==============================] - 1s 161us/sample - loss: 0.6931 - acc: 0.5075 - val_loss: 0.6928 - val_acc: 0.5180\n",
      "Epoch 3/40\n",
      "4000/4000 [==============================] - 1s 149us/sample - loss: 0.6931 - acc: 0.5075 - val_loss: 0.6928 - val_acc: 0.5180\n",
      "Epoch 4/40\n",
      "4000/4000 [==============================] - 1s 148us/sample - loss: 0.6930 - acc: 0.5075 - val_loss: 0.6927 - val_acc: 0.5180\n",
      "Epoch 5/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6929 - acc: 0.5075 - val_loss: 0.6926 - val_acc: 0.5180\n",
      "Epoch 6/40\n",
      "4000/4000 [==============================] - 1s 161us/sample - loss: 0.6929 - acc: 0.5075 - val_loss: 0.6927 - val_acc: 0.5180\n",
      "Epoch 7/40\n",
      "4000/4000 [==============================] - 1s 162us/sample - loss: 0.6928 - acc: 0.5075 - val_loss: 0.6926 - val_acc: 0.5180\n",
      "Epoch 8/40\n",
      "4000/4000 [==============================] - 1s 157us/sample - loss: 0.6927 - acc: 0.5075 - val_loss: 0.6924 - val_acc: 0.5180\n",
      "Epoch 9/40\n",
      "4000/4000 [==============================] - 1s 148us/sample - loss: 0.6926 - acc: 0.5075 - val_loss: 0.6923 - val_acc: 0.5180\n",
      "Epoch 10/40\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6924 - acc: 0.5075 - val_loss: 0.6922 - val_acc: 0.5180\n",
      "Epoch 11/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6923 - acc: 0.5075 - val_loss: 0.6920 - val_acc: 0.5180\n",
      "Epoch 12/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6921 - acc: 0.5075 - val_loss: 0.6919 - val_acc: 0.5180\n",
      "Epoch 13/40\n",
      "4000/4000 [==============================] - 1s 148us/sample - loss: 0.6917 - acc: 0.5365 - val_loss: 0.6918 - val_acc: 0.6060\n",
      "Epoch 14/40\n",
      "4000/4000 [==============================] - 1s 149us/sample - loss: 0.6914 - acc: 0.5505 - val_loss: 0.6914 - val_acc: 0.5180\n",
      "Epoch 15/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6910 - acc: 0.5190 - val_loss: 0.6911 - val_acc: 0.5240\n",
      "Epoch 16/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6906 - acc: 0.5088 - val_loss: 0.6908 - val_acc: 0.5240\n",
      "Epoch 17/40\n",
      "4000/4000 [==============================] - 1s 147us/sample - loss: 0.6900 - acc: 0.5860 - val_loss: 0.6904 - val_acc: 0.6320\n",
      "Epoch 18/40\n",
      "4000/4000 [==============================] - 1s 148us/sample - loss: 0.6895 - acc: 0.6532 - val_loss: 0.6899 - val_acc: 0.6360\n",
      "Epoch 19/40\n",
      "4000/4000 [==============================] - 1s 149us/sample - loss: 0.6888 - acc: 0.6403 - val_loss: 0.6894 - val_acc: 0.6260\n",
      "Epoch 20/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6880 - acc: 0.6590 - val_loss: 0.6888 - val_acc: 0.6340\n",
      "Epoch 21/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6873 - acc: 0.6407 - val_loss: 0.6883 - val_acc: 0.6140\n",
      "Epoch 22/40\n",
      "4000/4000 [==============================] - 1s 149us/sample - loss: 0.6862 - acc: 0.6593 - val_loss: 0.6873 - val_acc: 0.6400\n",
      "Epoch 23/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6851 - acc: 0.6695 - val_loss: 0.6865 - val_acc: 0.6360\n",
      "Epoch 24/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6838 - acc: 0.6550 - val_loss: 0.6859 - val_acc: 0.6020\n",
      "Epoch 25/40\n",
      "4000/4000 [==============================] - 1s 149us/sample - loss: 0.6824 - acc: 0.6535 - val_loss: 0.6846 - val_acc: 0.6280\n",
      "Epoch 26/40\n",
      "4000/4000 [==============================] - 1s 153us/sample - loss: 0.6808 - acc: 0.6628 - val_loss: 0.6835 - val_acc: 0.6120\n",
      "Epoch 27/40\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6790 - acc: 0.6507 - val_loss: 0.6822 - val_acc: 0.6120\n",
      "Epoch 28/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6768 - acc: 0.6595 - val_loss: 0.6805 - val_acc: 0.6160\n",
      "Epoch 29/40\n",
      "4000/4000 [==============================] - 1s 147us/sample - loss: 0.6745 - acc: 0.6680 - val_loss: 0.6789 - val_acc: 0.6160\n",
      "Epoch 30/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6720 - acc: 0.6720 - val_loss: 0.6769 - val_acc: 0.6280\n",
      "Epoch 31/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6694 - acc: 0.6587 - val_loss: 0.6753 - val_acc: 0.6160\n",
      "Epoch 32/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6662 - acc: 0.6798 - val_loss: 0.6727 - val_acc: 0.6440\n",
      "Epoch 33/40\n",
      "4000/4000 [==============================] - 1s 146us/sample - loss: 0.6633 - acc: 0.6762 - val_loss: 0.6709 - val_acc: 0.6260\n",
      "Epoch 34/40\n",
      "4000/4000 [==============================] - 1s 148us/sample - loss: 0.6595 - acc: 0.6827 - val_loss: 0.6680 - val_acc: 0.6440\n",
      "Epoch 35/40\n",
      "4000/4000 [==============================] - 1s 162us/sample - loss: 0.6559 - acc: 0.6990 - val_loss: 0.6653 - val_acc: 0.6460\n",
      "Epoch 36/40\n",
      "4000/4000 [==============================] - 1s 162us/sample - loss: 0.6518 - acc: 0.7045 - val_loss: 0.6626 - val_acc: 0.6400\n",
      "Epoch 37/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6477 - acc: 0.7090 - val_loss: 0.6601 - val_acc: 0.6420\n",
      "Epoch 38/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6432 - acc: 0.6935 - val_loss: 0.6562 - val_acc: 0.6540\n",
      "Epoch 39/40\n",
      "4000/4000 [==============================] - 1s 150us/sample - loss: 0.6385 - acc: 0.7450 - val_loss: 0.6528 - val_acc: 0.6640\n",
      "Epoch 40/40\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.6335 - acc: 0.7053 - val_loss: 0.6499 - val_acc: 0.6620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain,\n",
    "                    ytrain,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(Xval, yval),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy =  0.654\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.array(model.predict(Xtest) > 0.5, dtype=int).squeeze()\n",
    "print('Test Set Accuracy = %6.3f' % (np.sum(np.equal(test_pred, ytest))/len(ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "Basic models from the Learn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decisiton Tree Accuracy =  0.576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state=1)\n",
    "dt_model.fit(Xtrain, ytrain)\n",
    "dt_pred = dt_model.predict(Xtest)\n",
    "print('Decisiton Tree Accuracy = %6.3f' % (np.sum(np.equal(dt_pred, ytest))/len(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tree Accuracy =  0.004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(Xtrain, ytrain)\n",
    "forest_preds = forest_model.predict(Xtest)\n",
    "print('Forest Tree Accuracy = %6.3f' % (np.sum(np.equal(forest_preds, ytest))/len(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:0.498099\n",
      "Will train until validation_0-rmse hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-rmse:0.497101\n",
      "[2]\tvalidation_0-rmse:0.496042\n",
      "[3]\tvalidation_0-rmse:0.495215\n",
      "[4]\tvalidation_0-rmse:0.49481\n",
      "[5]\tvalidation_0-rmse:0.494227\n",
      "[6]\tvalidation_0-rmse:0.494191\n",
      "[7]\tvalidation_0-rmse:0.494109\n",
      "[8]\tvalidation_0-rmse:0.493912\n",
      "[9]\tvalidation_0-rmse:0.493585\n",
      "[10]\tvalidation_0-rmse:0.493387\n",
      "[11]\tvalidation_0-rmse:0.493721\n",
      "[12]\tvalidation_0-rmse:0.493443\n",
      "[13]\tvalidation_0-rmse:0.494047\n",
      "[14]\tvalidation_0-rmse:0.494341\n",
      "[15]\tvalidation_0-rmse:0.494411\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-rmse:0.493387\n",
      "\n",
      "Forest Tree Accuracy =  0.000\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500)\n",
    "xgb_model.fit(Xtrain, ytrain, early_stopping_rounds=5,\n",
    "             eval_set=[(Xval, yval)])\n",
    "xgb_pred = xgb_model.predict(Xtest)\n",
    "print('Forest Tree Accuracy = %6.3f' % (np.sum(np.equal(xgb_pred, ytest))/len(ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "Following: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 13522)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_data['text'])\n",
    "X_train_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 13522)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 13522)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(train_data['text'], ytrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Bayes Accuracy =  0.790\n"
     ]
    }
   ],
   "source": [
    "mnb_pred = text_clf.predict(test_data['text'])\n",
    "print('Multinomial Bayes Accuracy = %6.3f' % (np.sum(np.equal(mnb_pred, ytest))/len(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy =  0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "svm_model.fit(train_data['text'], ytrain)  \n",
    "svm_pred = svm_model.predict(test_data['text'])\n",
    "print('SVM Accuracy = %6.3f' % (np.sum(np.equal(svm_pred, ytest))/len(ytest)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Documents\\WPy64-3680\\python-3.6.8.amd64\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(svm_model, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_data['text'], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS Accuracy =  0.786\n"
     ]
    }
   ],
   "source": [
    "gs_pred = gs_clf.predict(test_data['text'])\n",
    "print('GS Accuracy = %6.3f' % (np.sum(np.equal(gs_pred, ytest))/len(ytest)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
